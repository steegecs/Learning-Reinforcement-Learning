{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randint\n",
    "from torch import nn, optim\n",
    "import torch \n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from scores.score_logger import ScoreLogger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"CartPole-v1\"\n",
    "GAMMA = 0.95\n",
    "MEMORY = 1000000\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.01\n",
    "EXPLORATION_DECAY = 0.995\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(observation_space, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, action_space)\n",
    "        )\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "        self.discount = GAMMA\n",
    "        self.memory = deque(maxlen=MEMORY)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # Sometimes act randomly. Do so less and less as the exploration rate decays.\n",
    "    def act(self, state):\n",
    "        if (np.random.rand() < self.exploration_rate):\n",
    "            return random.randrange(self.action_space)\n",
    "        # print(self.model(torch.from_numpy(state)).argmax().item())\n",
    "        return self.model(torch.from_numpy(state)).argmax().item()\n",
    "    \n",
    "    def get_q_next(self, next_state):\n",
    "        return self.discount * self.model(torch.from_numpy(next_state)).max()\n",
    "\n",
    "    def experience_replay(self):\n",
    "        # Don't replay if we don't have enough memory\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "            \n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        # self.optimizer.zero_grad()\n",
    "        for state, action, reward, next_state, terminal in batch:    \n",
    "            q_update = reward\n",
    "            # Update the q value for the action we took\n",
    "            # Bellman inspired update\n",
    "            # Current state rewards plus next state rewards discounted by gamma\n",
    "            if not terminal:\n",
    "                q_update = reward + self.get_q_next(next_state)\n",
    "            else: \n",
    "                # create long tensor\n",
    "                q_update = torch.tensor(q_update, dtype=torch.float32)\n",
    "            \n",
    "            ## Get the q_values for the current state\n",
    "            q_values = self.model(torch.from_numpy(state))\n",
    "            prediction, _ = torch.max(q_values, axis=1)  \n",
    "\n",
    "            loss = self.loss_fn(prediction, q_update.reshape(1))\n",
    "\n",
    "            # We reset the optimizer each time because we are training in batches of one\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Back propagate the loss\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            # Update the weights\n",
    "            self.optimizer.step()   \n",
    "            \n",
    "        # Decay the exploration rate\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/opt/anaconda3/envs/aiGym-3-9/lib/python3.9/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/Users/chris/opt/anaconda3/envs/aiGym-3-9/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1, exploration: 0.9229311239742362, score: 36\n",
      "Scores: (min: 36, avg: 36, max: 36)\n",
      "\n",
      "1\n",
      "Run: 2, exploration: 0.8690529955452602, score: 13\n",
      "Scores: (min: 13, avg: 24.5, max: 36)\n",
      "\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/repos/Learning-Reinforcement-Learning/scores/score_logger.py:31: RankWarning: Polyfit may be poorly conditioned\n",
      "  self._save_png(input_path=SCORES_CSV_PATH,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Run: 3, exploration: 0.8142285204175609, score: 14\n",
      "Scores: (min: 13, avg: 21, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 4, exploration: 0.6935613678313175, score: 33\n",
      "Scores: (min: 13, avg: 24, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 5, exploration: 0.6629680834613705, score: 10\n",
      "Scores: (min: 10, avg: 21.2, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 6, exploration: 0.6305556603555866, score: 11\n",
      "Scores: (min: 10, avg: 19.5, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 7, exploration: 0.6057704364907278, score: 9\n",
      "Scores: (min: 9, avg: 18, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 8, exploration: 0.5590843898207511, score: 17\n",
      "Scores: (min: 9, avg: 17.875, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 9, exploration: 0.5185893309484582, score: 16\n",
      "Scores: (min: 9, avg: 17.666666666666668, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 10, exploration: 0.4932355662165453, score: 11\n",
      "Scores: (min: 9, avg: 17, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 11, exploration: 0.46912134373457726, score: 11\n",
      "Scores: (min: 9, avg: 16.454545454545453, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 12, exploration: 0.446186062443672, score: 11\n",
      "Scores: (min: 9, avg: 16, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 13, exploration: 0.42650460709830135, score: 10\n",
      "Scores: (min: 9, avg: 15.538461538461538, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 14, exploration: 0.40769130904675194, score: 10\n",
      "Scores: (min: 9, avg: 15.142857142857142, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 15, exploration: 0.39166620452737816, score: 9\n",
      "Scores: (min: 9, avg: 14.733333333333333, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 16, exploration: 0.37627099809304654, score: 9\n",
      "Scores: (min: 9, avg: 14.375, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 17, exploration: 0.3403786882983606, score: 21\n",
      "Scores: (min: 9, avg: 14.764705882352942, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 18, exploration: 0.31890579420988907, score: 14\n",
      "Scores: (min: 9, avg: 14.722222222222221, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 19, exploration: 0.3033145315372582, score: 11\n",
      "Scores: (min: 9, avg: 14.526315789473685, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 20, exploration: 0.28134514724562876, score: 16\n",
      "Scores: (min: 9, avg: 14.6, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 21, exploration: 0.2649210072611673, score: 13\n",
      "Scores: (min: 9, avg: 14.523809523809524, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 22, exploration: 0.2532352299289372, score: 10\n",
      "Scores: (min: 9, avg: 14.318181818181818, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 23, exploration: 0.23965031961336, score: 12\n",
      "Scores: (min: 9, avg: 14.217391304347826, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 24, exploration: 0.2290792429684691, score: 10\n",
      "Scores: (min: 9, avg: 14.041666666666666, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 25, exploration: 0.2167901907234072, score: 12\n",
      "Scores: (min: 9, avg: 13.96, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 26, exploration: 0.20209834538617025, score: 15\n",
      "Scores: (min: 9, avg: 14, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 27, exploration: 0.192217783647157, score: 11\n",
      "Scores: (min: 9, avg: 13.88888888888889, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 28, exploration: 0.18373897616330553, score: 10\n",
      "Scores: (min: 9, avg: 13.75, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 29, exploration: 0.1756341724525918, score: 10\n",
      "Scores: (min: 9, avg: 13.620689655172415, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 30, exploration: 0.1678868750508869, score: 10\n",
      "Scores: (min: 9, avg: 13.5, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 31, exploration: 0.15967890763313974, score: 11\n",
      "Scores: (min: 9, avg: 13.419354838709678, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 32, exploration: 0.1526354036900377, score: 10\n",
      "Scores: (min: 9, avg: 13.3125, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 33, exploration: 0.14372497725712216, score: 13\n",
      "Scores: (min: 9, avg: 13.303030303030303, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 34, exploration: 0.13807558583895513, score: 9\n",
      "Scores: (min: 9, avg: 13.176470588235293, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 35, exploration: 0.13331482894782642, score: 8\n",
      "Scores: (min: 8, avg: 13.028571428571428, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 36, exploration: 0.1261630989318213, score: 12\n",
      "Scores: (min: 8, avg: 13, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 37, exploration: 0.12181307688414106, score: 8\n",
      "Scores: (min: 8, avg: 12.864864864864865, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 38, exploration: 0.11643985070121858, score: 10\n",
      "Scores: (min: 8, avg: 12.789473684210526, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 39, exploration: 0.11186295456362313, score: 9\n",
      "Scores: (min: 8, avg: 12.692307692307692, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 40, exploration: 0.10586201936274783, score: 12\n",
      "Scores: (min: 8, avg: 12.675, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 41, exploration: 0.10221196540767843, score: 8\n",
      "Scores: (min: 8, avg: 12.560975609756097, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 42, exploration: 0.09770335251664321, score: 10\n",
      "Scores: (min: 8, avg: 12.5, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 43, exploration: 0.09339361644125409, score: 10\n",
      "Scores: (min: 8, avg: 12.44186046511628, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 44, exploration: 0.09017346495423652, score: 8\n",
      "Scores: (min: 8, avg: 12.340909090909092, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 45, exploration: 0.08662902049662846, score: 9\n",
      "Scores: (min: 8, avg: 12.266666666666667, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 46, exploration: 0.08280777787605056, score: 10\n",
      "Scores: (min: 8, avg: 12.217391304347826, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 47, exploration: 0.07995261925574046, score: 8\n",
      "Scores: (min: 8, avg: 12.127659574468085, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 48, exploration: 0.07604374613140748, score: 11\n",
      "Scores: (min: 8, avg: 12.104166666666666, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 49, exploration: 0.0716045256805401, score: 13\n",
      "Scores: (min: 8, avg: 12.122448979591837, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 50, exploration: 0.06844601986126451, score: 10\n",
      "Scores: (min: 8, avg: 12.08, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 51, exploration: 0.06542683706543727, score: 10\n",
      "Scores: (min: 8, avg: 12.03921568627451, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 52, exploration: 0.06285510723190912, score: 9\n",
      "Scores: (min: 8, avg: 11.98076923076923, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 53, exploration: 0.06038446427088321, score: 9\n",
      "Scores: (min: 8, avg: 11.924528301886792, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 54, exploration: 0.05830244700006734, score: 8\n",
      "Scores: (min: 8, avg: 11.851851851851851, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 55, exploration: 0.05601075525639029, score: 9\n",
      "Scores: (min: 8, avg: 11.8, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 56, exploration: 0.05354009722551939, score: 10\n",
      "Scores: (min: 8, avg: 11.767857142857142, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 57, exploration: 0.051178420962124486, score: 10\n",
      "Scores: (min: 8, avg: 11.736842105263158, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 58, exploration: 0.0494138221100385, score: 8\n",
      "Scores: (min: 8, avg: 11.672413793103448, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 59, exploration: 0.046997986793891174, score: 11\n",
      "Scores: (min: 8, avg: 11.661016949152541, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 60, exploration: 0.044924885780066794, score: 10\n",
      "Scores: (min: 8, avg: 11.633333333333333, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 61, exploration: 0.043159025252331236, score: 9\n",
      "Scores: (min: 8, avg: 11.59016393442623, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 62, exploration: 0.04146257532741124, score: 9\n",
      "Scores: (min: 8, avg: 11.548387096774194, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 63, exploration: 0.039435475429100995, score: 11\n",
      "Scores: (min: 8, avg: 11.53968253968254, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 64, exploration: 0.03769595998025326, score: 10\n",
      "Scores: (min: 8, avg: 11.515625, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 65, exploration: 0.036033175291307735, score: 10\n",
      "Scores: (min: 8, avg: 11.492307692307692, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 66, exploration: 0.034443736736092176, score: 10\n",
      "Scores: (min: 8, avg: 11.469696969696969, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 67, exploration: 0.03275978694079333, score: 11\n",
      "Scores: (min: 8, avg: 11.462686567164178, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 68, exploration: 0.03147209942303359, score: 9\n",
      "Scores: (min: 8, avg: 11.426470588235293, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 69, exploration: 0.03038696179137978, score: 8\n",
      "Scores: (min: 8, avg: 11.376811594202898, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 70, exploration: 0.02904658009432929, score: 10\n",
      "Scores: (min: 8, avg: 11.357142857142858, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 71, exploration: 0.027765323199097504, score: 10\n",
      "Scores: (min: 8, avg: 11.338028169014084, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 72, exploration: 0.026673952849996664, score: 9\n",
      "Scores: (min: 8, avg: 11.305555555555555, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 73, exploration: 0.025754252208694463, score: 8\n",
      "Scores: (min: 8, avg: 11.26027397260274, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 74, exploration: 0.024741930939380097, score: 9\n",
      "Scores: (min: 8, avg: 11.22972972972973, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 75, exploration: 0.023769400938086327, score: 9\n",
      "Scores: (min: 8, avg: 11.2, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 76, exploration: 0.02260731802731653, score: 11\n",
      "Scores: (min: 8, avg: 11.197368421052632, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 77, exploration: 0.02171869316274056, score: 9\n",
      "Scores: (min: 8, avg: 11.168831168831169, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 78, exploration: 0.020760672449809284, score: 10\n",
      "Scores: (min: 8, avg: 11.153846153846153, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 79, exploration: 0.019844910434467605, score: 10\n",
      "Scores: (min: 8, avg: 11.139240506329115, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 80, exploration: 0.018969543067746772, score: 10\n",
      "Scores: (min: 8, avg: 11.125, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 81, exploration: 0.018223908064988973, score: 9\n",
      "Scores: (min: 8, avg: 11.098765432098766, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 82, exploration: 0.0175075817047932, score: 9\n",
      "Scores: (min: 8, avg: 11.073170731707316, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 83, exploration: 0.016735314893855303, score: 10\n",
      "Scores: (min: 8, avg: 11.060240963855422, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 84, exploration: 0.015997113097568336, score: 10\n",
      "Scores: (min: 8, avg: 11.047619047619047, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 85, exploration: 0.015368315270123408, score: 9\n",
      "Scores: (min: 8, avg: 11.023529411764706, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 86, exploration: 0.014838425699981627, score: 8\n",
      "Scores: (min: 8, avg: 10.988372093023257, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 87, exploration: 0.014255172347583332, score: 9\n",
      "Scores: (min: 8, avg: 10.96551724137931, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 88, exploration: 0.013694844909292236, score: 9\n",
      "Scores: (min: 8, avg: 10.943181818181818, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 89, exploration: 0.013156542237201536, score: 9\n",
      "Scores: (min: 8, avg: 10.92134831460674, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 90, exploration: 0.012576201611761997, score: 10\n",
      "Scores: (min: 8, avg: 10.911111111111111, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 91, exploration: 0.01208186940302195, score: 9\n",
      "Scores: (min: 8, avg: 10.89010989010989, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 92, exploration: 0.011606967888870102, score: 9\n",
      "Scores: (min: 8, avg: 10.869565217391305, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 93, exploration: 0.011094979641301777, score: 10\n",
      "Scores: (min: 8, avg: 10.86021505376344, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 94, exploration: 0.010605575411209664, score: 10\n",
      "Scores: (min: 8, avg: 10.851063829787234, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 95, exploration: 0.010188702520663827, score: 9\n",
      "Scores: (min: 8, avg: 10.83157894736842, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 96, exploration: 0.01, score: 9\n",
      "Scores: (min: 8, avg: 10.8125, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 97, exploration: 0.01, score: 9\n",
      "Scores: (min: 8, avg: 10.793814432989691, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 98, exploration: 0.01, score: 11\n",
      "Scores: (min: 8, avg: 10.795918367346939, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 99, exploration: 0.01, score: 10\n",
      "Scores: (min: 8, avg: 10.787878787878787, max: 36)\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Run: 100, exploration: 0.01, score: 9\n",
      "Scores: (min: 8, avg: 10.77, max: 36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create environment and a way to track the score\n",
    "env = gym.make(ENV_NAME)\n",
    "score_logger = ScoreLogger(ENV_NAME)\n",
    "\n",
    "# Get the action and state space sizes from the environment\n",
    "action_space = env.action_space.n\n",
    "observation_space = env.observation_space.shape[0]\n",
    "\n",
    "# Reset the environment and get the first state\n",
    "state, info = env.reset(seed=42, return_info=True)\n",
    "\n",
    "# Create the agent\n",
    "dqn = DQN(observation_space, action_space)\n",
    "\n",
    "run = 0 # run is the number of episodes\n",
    "while run < 100:\n",
    "    run += 1\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, observation_space])\n",
    "    step = 0\n",
    "    while(True): \n",
    "        step += 1\n",
    "\n",
    "        # Predict action then take action in environment\n",
    "        action = dqn.act(state)\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "\n",
    "        # Get set reward negative if game over\n",
    "        reward = reward if not terminal else -reward\n",
    "        state_next = np.reshape(state_next, [1, observation_space])\n",
    "\n",
    "        # Store experience in memory\n",
    "        dqn.remember(state, action, reward, state_next, terminal)\n",
    "        state = state_next\n",
    "\n",
    "        if terminal:\n",
    "            print(\"Run: \" + str(run) + \", exploration: \" + str(dqn.exploration_rate) + \", score: \" + str(step))\n",
    "            score_logger.add_score(step, run)\n",
    "            break\n",
    "        \n",
    "        # Experience replay - train model\n",
    "        dqn.experience_replay()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, i = torch.max(dqn.model(torch.from_numpy(state).float()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values = dqn.model(torch.from_numpy(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values[0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.reshape(state, [1, observation_space])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.model(state).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.model(torch.from_numpy(state).float()).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aiGym-3-9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d989930d2ce6478f400bece301e290be5d0537f88c7447ba48889ddf48d55e98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
