{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Tracking a Nonstationary Problem.\n",
    "\n",
    "![](images/K-Bandits-Non-Stationary.png)\n",
    "![](images/Stochastic-Theory-Convergence.png)\n",
    "\n",
    "- Stochastic Theory tells us the above two conditions must be met for convergence. \n",
    "    - The first condition is required to guarantee that the steps are large enough to eventually\n",
    "    overcome any initial conditions or random fluctuations. \n",
    "    - The second condition guarantees\n",
    "    that eventually the steps become small enough to assure convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Optimistic Initial Values\n",
    "\n",
    "- What is optimistic initial values? \n",
    "    - Biased by initital estimates.\n",
    "    - They are optimistic about the value of early observation \n",
    "\n",
    "- methods\n",
    "    - Optimistic Initial Values\n",
    "        - You can bias you state evaluator by assigning an arbitrary positive value. \n",
    "            - This encourages exploration. \n",
    "        - Can in some cases be effective in stationary problems. \n",
    "            - This method cannot help when you confront situations that encourage a new need for exploration in an unfamiliar or different state space. \n",
    "            - sample-average methods also suffer from the notion of treating the starting states as a 'special' point in time. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Upper Confidence-Bound Action Selection\n",
    "- e-greedy policies indiscriminately chooses non-greedy actions, without paying attention to particular uncertainty. \n",
    "- UCB (Upper Confidence Bound)\n",
    "    -  c controled the degree of exploration\n",
    "    - N(t)(a) is the number of times an action \"a\" was taken\n",
    "\n",
    "![](images/Upper-Confidence-Bound.png)\n",
    "\n",
    "- What is inside the square root can be thought of as an uncertainty parameter. \n",
    "    - This causes the decision algorithm to have uncertainty about an action over time if the action is not chosen.\n",
    "    - However, this happens with decreasing frequency due to the choice of using the natural log in the numerator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56941cacf15e8b05765996006082865469347c2b4cdce983108d1335de8b4245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
