{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.4 The policy iteration algorithm on page 80 has a subtle bug in that it may\n",
    "never terminate if the policy continually switches between two or more policies that are\n",
    "equally good. This is okay for pedagogy, but not for actual use. Modify the pseudocode\n",
    "so that convergence is guaranteed.\n",
    "- An approcach like policy evaluation should be used as well for this situations. Instead of at the end checking if the old action does not equal the policy, check if the change in V(s) is below a certain threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.5 How would policy iteration be defined for action values? Give a complete algorithm for computing q*, analogous to that on page 80 for computing v*. Please pay special attention to this exercise,because the ideas involved will be used throughout the rest of the book.\n",
    "- This is very similar to policy iteration for state values. Just replace the relevant parts of the state update function and correponding image of Q*(s,a) calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.8 Why does the optimal\n",
    "policy for the gambler’s problem have such a curious form? In particular, for capital of 50\n",
    "it bets it all on one flip, but for capital of 51 it does not. Why is this a good policy?\n",
    "- The expected value is not in the favor of the gambler. Therefore it makes sense to gamble it all when you have fifty dollars, because your balance is more likely to decrease over time as you gamble more and more. Getting to 100 from 25 has a chance of .4*.4 (16%) and 40% if you are at fifty. These are optimal policies, because you want to take as few steps to 100 as you can. The reason there is a spike down before and after these probabilities is because gambling it all at 51 still requires the same amount of steps as at 50. You can always fall back and gamble your 50 dollars. S0, what the polocy is trying to do is get back to 50 again with the extra 1 dollar over 50. If it fails, it can fall back to gambling it all at 50 and still have a 40% chance to win in one shot. This reasoning also explains the spikes before and after 25 dollars held. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.9 (programming) Implement value iteration for the gambler’s problem and\n",
    "solve it for ph = 0.25 and ph = 0.55. In programming, you may find it convenient to\n",
    "introduce two dummy states corresponding to termination with capital of 0 and 100,\n",
    "giving them values of 0 and 1 respectively. Show your results graphically, as in Figure 4.3.\n",
    "Are your results stable as ✓ ! 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.10 What is the analog of the value iteration update (4.10) for action values,\n",
    "qk+1(s, a)?\n",
    "\n",
    "![](images/Action-Value-Update.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56941cacf15e8b05765996006082865469347c2b4cdce983108d1335de8b4245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
