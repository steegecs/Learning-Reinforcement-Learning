{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Policy Evaluation Algorithm\n",
    "class GridIterativePolicyEvaluation(): \n",
    "    def __init__(self, init_state_values, starting_state, grid_size, terminal_states):\n",
    "        #Initialize state values randomly\n",
    "        self.evaluated_state_values = init_state_values\n",
    "\n",
    "        #Undicounted\n",
    "        self.discount = 1\n",
    "        self.step_cost = -1\n",
    "\n",
    "        #Grid Size\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        #Termination States\n",
    "        self.terminal_states = terminal_states\n",
    "\n",
    "        #When to stop\n",
    "        self.termination_diff = 0.00000001\n",
    "        self.diff = 100\n",
    "\n",
    "        # select random integer between 0 and 3\n",
    "        self.current_state = starting_state\n",
    "        self.action_probability = 0.25\n",
    "\n",
    "    def get_starting_state_random(self): \n",
    "        # Select a random starting state - Don't let it be the termination state\n",
    "        x = np.random.randint(0, self.grid_size[0])\n",
    "        y = np.random.randint(0, self.grid_size[1])\n",
    "        while ([x, y] in self.terminal_states):\n",
    "            x = np.random.randint(0, self.grid_size[0])\n",
    "            y = np.random.randint(0, self.grid_size[1])\n",
    "        return [x, y]\n",
    "\n",
    "    def get_step_right(self):\n",
    "        return [self.current_state[0] + 1, self.current_state[1]]\n",
    "    \n",
    "    def get_step_left(self):\n",
    "        return [self.current_state[0] - 1, self.current_state[1]]\n",
    "    def get_step_up(self):\n",
    "        return [self.current_state[0], self.current_state[1] + 1]\n",
    "    \n",
    "    def get_step_down(self):\n",
    "        return [self.current_state[0], self.current_state[1] - 1]\n",
    "    \n",
    "    def is_out_of_range(self, state):\n",
    "        if (state[0] > self.grid_size[0] - 1 or state[0] < 0 or state[1] > self.grid_size[1] -1 or state[1] < 0):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_state_value(self):\n",
    "        expected_value = 0.0\n",
    "\n",
    "        # Get expected \n",
    "        if (self.is_out_of_range(self.get_step_right())):\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.current_state[1]])\n",
    "        else: \n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.get_step_right()[0], self.current_state[1]])\n",
    "\n",
    "        if (self.is_out_of_range(self.get_step_left())):\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.current_state[1]])\n",
    "        else:\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.get_step_left()[0], self.current_state[1]])\n",
    "        \n",
    "        if (self.is_out_of_range(self.get_step_up())):\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.current_state[1]])\n",
    "        else:\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.get_step_up()[1]])\n",
    "        \n",
    "        if (self.is_out_of_range(self.get_step_down())):\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.current_state[1]])\n",
    "        else:\n",
    "            expected_value += self.action_probability * (self.step_cost + self.discount * self.evaluated_state_values[self.current_state[0], self.get_step_down()[1]])\n",
    "\n",
    "        return expected_value\n",
    "    \n",
    "    def get_next_state(self, step):\n",
    "        if (self.is_out_of_range(step)):\n",
    "            return self.current_state\n",
    "        else: \n",
    "            return step\n",
    "\n",
    "    def take_step(self): \n",
    "        action_probability = np.random.rand()\n",
    "        #take one action randomly\n",
    "        if (action_probability < self.action_probability):\n",
    "            return self.get_next_state(self.get_step_up())\n",
    "        elif (action_probability < 2 * self.action_probability):\n",
    "            return self.get_next_state(self.get_step_down())\n",
    "        elif (action_probability < 3 * self.action_probability):\n",
    "            return self.get_next_state(self.get_step_right())\n",
    "        else:\n",
    "            return self.get_next_state(self.get_step_left())\n",
    "\n",
    "    \n",
    "    def iterative_evaluation(self):\n",
    "        while (self.diff > self.termination_diff):\n",
    "            self.diff = 0.0\n",
    "            while (True):\n",
    "                if (self.current_state in self.terminal_states):\n",
    "                    break\n",
    "\n",
    "                old_state_value = self.evaluated_state_values[self.current_state[0]][self.current_state[1]]\n",
    "                new_state_value = self.get_state_value()\n",
    "\n",
    "                self.evaluated_state_values[self.current_state[0]][self.current_state[1]] = new_state_value\n",
    "                self.diff = max(self.diff, abs(old_state_value - new_state_value))\n",
    "\n",
    "                self.current_state = self.take_step()\n",
    "\n",
    "            self.current_state = self.get_starting_state_random()\n",
    "\n",
    "        return self.evaluated_state_values\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "grid_size = [5, 5]\n",
    "terminal_states  = [[4,4], [0,0]]\n",
    "\n",
    "#Initialize a random number\n",
    "init_state_values = np.random.rand(grid_size[0], grid_size[1])*-100\n",
    "for terminal_state in terminal_states:\n",
    "    init_state_values[terminal_state[0]][terminal_state[1]] = 0\n",
    "\n",
    "x = np.random.randint(0, grid_size[0])\n",
    "y = np.random.randint(0, grid_size[1])\n",
    "while ([x, y] in terminal_states):\n",
    "    x = np.random.randint(0, grid_size[0])\n",
    "    y = np.random.randint(0, grid_size[1])\n",
    "starting_state = [x, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.90070414013664\n",
      "56.005698983652636\n",
      "96.64274793793199\n",
      "2.3913057003911105\n",
      "72.86974733721938\n",
      "10.954488800697831\n",
      "4.627037050170608\n",
      "0.0017866615361215032\n",
      "0.12039592203896787\n",
      "70.72325540407014\n",
      "0.02555782794958983\n",
      "0.0980261360943071\n",
      "0.11804323960930008\n",
      "0.01227148715341353\n",
      "1.6689941584324686e-05\n",
      "0.04161998938907341\n",
      "1.8987660864278055e-05\n",
      "0.0026476570849209846\n",
      "6.965097613065296e-05\n",
      "6.603606550470431e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.08256748, -1.11037914, -1.11109238, -1.11111041],\n",
       "       [-1.08256741, -1.10968305, -1.111057  , -1.11110768, -1.11109764],\n",
       "       [-1.1103774 , -1.11105684, -1.11110573, -1.11105686, -1.11037744],\n",
       "       [-1.11109218, -1.11110745, -1.11105679, -1.10968112, -1.0825656 ],\n",
       "       [-1.11111012, -1.11109218, -1.1103773 , -1.0825656 ,  0.        ]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridIterativePolicyEvaluation(init_state_values, starting_state, grid_size, terminal_states).iterative_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56941cacf15e8b05765996006082865469347c2b4cdce983108d1335de8b4245"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
